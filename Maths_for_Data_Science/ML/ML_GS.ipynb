{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le perceptron monocouche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut classer un input $X$ (plusieurs vecteurs de réels) de façon binaire (le nombre de classe est de 2); <br>\n",
    "=> on cherche à approcher $f: \\mathcal{X} \\to \\mathcal{Y}$ où $X \\in \\mathcal{X} \\subset \\mathbb{R}^p$ et $\\mathcal{Y}=\\{-1,1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le perceptron monocouche, la classification se fait de manière <i>linéaire</i>; on cherche un <i>hyperplan</i> qui sépare au mieux les observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{H}=\\{ x \\in \\mathbb{R}^p, \\hat{f}_\\omega(x):=\\omega_0+\\Sigma_{i=1}^p \\omega_ix_i=0 \\}$$<br>\n",
    "<center>($x$ est l'ensemble des variables explicatives pour <u>une</u> observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi écrire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathcal{H}_\\omega:\\omega^Tx+\\omega_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>Classifieur Perceptron: $x \\mapsto sign(\\hat{f}_\\omega(x))$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les $\\omega$ doivent être tel que la fonction de perte $\\ell$ (risque) est minimisée:<br>\n",
    "$\\mathbb{E}[\\mathcal{\\ell}(\\hat{f}_\\omega(x),y)]$ est le risque <i>théorique</i> à minimiser<br>\n",
    "En machine learning on respecte la théorie ERM (Empiric Risk Minimisation) et donc se concentre sur le risque empirique<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fonction de perte (= risque empirique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\widehat{L}_n(\\hat{f}_\\omega(x))=\\frac{1}{n}\\Sigma \\mathbb{1} \\{ -Y_i (\\omega_0+\\Sigma_{i=1}^p \\omega_ix_i) >0 \\}$ --> Les résultats pris en compte sont lorsque le signe de $Y_i$ est différent du signe de $\\omega_0+\\Sigma_{i=1}^p \\omega_ix_i$<br>\n",
    "Problème: la fonction de perte $\\widehat{L}_n$ n'est pas continue (car présence d'une indicatrice), donc on ne peut pas appliquer la descente de gradient.<br>\n",
    "=> Rosenblatt utilise une fonction de perte lisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi prendre: $\\widehat{L}_n(\\hat{f}_\\omega(x))=-\\Sigma Y_i (\\omega_0+\\Sigma_{i=1}^p \\omega_ix_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut minimiser la fonction de perte $\\widehat{L}_n$ --> implique une somme (espérance => somme dans la grandeur empirique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Minimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel: descente de gradient globale:<br>\n",
    "$\\widehat{L}_n(\\hat{f}_\\omega(x))=\\Sigma_{i=1}^n \\mathcal{\\ell}(\\hat{f}_\\omega(x),y)$<br>\n",
    "$E=1000$<br>\n",
    "$\\epsilon$ = petite valeur<br>\n",
    "$\\omega_0$ = valeur initiale en $t_0$<br>\n",
    "$tant~que~(E>\\epsilon):$<br>\n",
    "$~~~~\\omega_{t+1}=\\omega_t-\\epsilon\\Sigma_{i=1}^n\\nabla_\\omega{\\mathcal{\\ell}(\\hat{f}_\\omega(x),y)}$<br>\n",
    "$~~~~calculer~E=L_n(\\omega_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descente de gradient stochastique:<br>\n",
    "$\\widehat{L}_n(f_\\omega(x))=\\Sigma_{i=1}^n \\mathcal{\\ell}(\\hat{f}_\\omega(x),y)$<br>\n",
    "$E=1000$<br>\n",
    "$\\epsilon$ = petite valeur<br>\n",
    "$\\omega_0$ = valeur initiale en $t_0$<br>\n",
    "$tant~que~(E>\\epsilon):$<br>\n",
    "$~~~~for~i=1~to~n:$<br>\n",
    "$~~~~~~~~~\\omega_{t+1}=\\omega_t-\\epsilon\\nabla_\\omega{\\mathcal{\\ell}(\\hat{f}_\\omega(x_i),y_i)}$<br>\n",
    "$~~~~~~~~~calculer~E=L_n(\\omega_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descente de gradient stochastique aléatoire:<br>\n",
    "$\\widehat{L}_n(f_\\omega(x))=\\Sigma_{i=1}^n \\mathcal{\\ell}(\\hat{f}_\\omega(x),y)$<br>\n",
    "$E=1000$<br>\n",
    "$\\epsilon$ = petite valeur<br>\n",
    "$\\omega_0$ = valeur initiale en $t_0$<br>\n",
    "$tant~que~(E>\\epsilon):$<br>\n",
    "$~~~~for~i=1~to~n:$<br>\n",
    "$~~~~~~~~~tirer~uniformément~i \\in \\{1,...,n\\}$<br>\n",
    "$~~~~~~~~~\\omega_{t+1}=\\omega_t-\\epsilon\\nabla_\\omega{\\mathcal{\\ell}(\\hat{f}_\\omega(x_i),y_i)}$<br>\n",
    "$~~~~~~~~~calculer~E=L_n(\\omega_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La descente de gradient stochastique permet de ne pas calculer le gradient sur toutes les observations (coûteux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: le tirage peut se faire avec ou sans remise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: le gradient est à dériver en fonction de $\\omega$, il comporte donc le nombre de composantes de $\\omega$ (ex: 3 composantes si $\\omega^T = [ \\omega_0~\\omega_1~\\omega_2 ]$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappel de notations: \n",
    "\n",
    "$x=(x_1,...,x_p)^T \\in \\mathcal{X}$ une observation<br>\n",
    "$\\mathcal{D}_n=\\{(x_i,y_i),i=1,...,n\\}$ ensemble d’apprentissage contenant les n exemples et leurs étiquettes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut approcher $f: \\mathcal{X} \\to \\mathcal{Y}$, $\\mathcal{X} \\in \\mathbb{R}^p$, $\\mathcal{Y}=\\{1,...,L\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque nouveau point $x \\in \\mathbb{R}^p$ on détermine l’ensemble de ses k-plus proches voisins parmi tous les points d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note la distance entre 2 points: $d: \\mathbb{R}^p \\times \\mathbb{R}^p \\to \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Attention: un \"point\" $i$ est une <u>observation</u> $x^T=(x_i^{(1)},...,x_i^{(p)})$; ici on calcule donc des distances entre des vecteurs de dimension $p$</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut prendre la distance euclidienne: $d(u,v)=||u-v||^2=\\Sigma_{i=1}^p(u_i-v_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc une matrice de distances avec en ligne l'échantillon de test (exposant $(t)$) et en colonne l'échantillon d'entraînement (exposant $(T)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_style(val):\n",
    "              return 'font-weight: bold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1^{(t)}$ | $x_2^{(t)}$ | $...$ | $x_m^{(t)}$\n",
    "------ | ----- | ----- | -----\n",
    "$d(x_1^{(t)},x_1^{(T)})$ | $d(x_2^{(t)},x_1^{(T)})$ | $...$ | $d(x_m^{(t)},x_1^{(T)})$\n",
    "$d(x_1^{(t)},x_2^{(T)})$ | $d(x_2^{(t)},x_1^{(T)})$ | $...$ | $...$\n",
    "$...$ | $...$ | $...$ | $...$\n",
    "$d(x_1^{(t)},x_n^{(T)})$ | $...$ | $...$ | $d(x_m^{(t)},x_n^{(T)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: pour cette matrice, l'échantillon d'apprentissage est de taille $n$, celui de test de taille $m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trie ensuite cette matrice sur les <b>colonnes</b> par ordre croissant pour trouver les points d'entraînement dont les distances avec le point testé sont les plus faibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque point testé, on garde les k plus petites distances et on regarde les classes associées à chacun des points sélectionnés (la fonction <i>argsort</i> permet de garder les indices au moment du tri). On définit le rang d'un voisin:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$r_k(x)=i^*$ si et seulement si $d(x_{i^*},x)=\\underset{1 \\le i \\le n \\\\\n",
    "i \\neq r_{1},...,r_{k-1}}{\\operatorname{min}}d(x_i,x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La règle la plus basique est de prendre la classe majoritaire parmi ces k voisins sélectionnés (schéma ci-dessous):\n",
    "\n",
    "$$\\widehat{f}_k(x)=\\underset{y \\in \\mathcal{Y}}{\\operatorname{argmax}}(\\Sigma_{j=1}^k \\mathbb{1}\\{y_{r_j}=y\\})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"TP_ML/KNN/KNN_pic.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque: la fonction <i>fit</i> du KNNClassifier est juste une affectation des données d'entraînement à l'objet (le calcul des distances se fera dans le <i>predict</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Homemade kNN classifier class \"\"\"\n",
    "    def __init__(self, n_neighbors=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    def fit(self, X, y): # L'entraînement sert simplement à \"enregistrer\" les données d'entraînement,\n",
    "                         # déjà classifiées\n",
    "        self.X = X\n",
    "        self.Y = y\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        n = len(self.X) # taille de l'échantillon dans X_train\n",
    "        m = len(X) # taille de l'échantillon dans X_test\n",
    "        dist_mat = []\n",
    "        for i in range(n): # On boucle sur tous les éléments de l'échantillon d'entraînement\n",
    "            dist_vect = []\n",
    "            for j in range(m): # On boucle sur tous les éléments de l'échantillon de test\n",
    "                dist_vect.append(euclidean_distance(self.X[i], X[j]))\n",
    "            dist_mat.append(dist_vect) # len(dist_vect) = m (nb de features; toutes les distances pour une observation)\n",
    "            \n",
    "        dist_mat = np.asarray(dist_mat) # dist_mat.shape = (n,m); T_test en colonne, X_train en ligne\n",
    "        \n",
    "        # dist_mat = metrics.pairwise.pairwise_distances(X, Y=self.X, metric='euclidean', n_jobs=1)\n",
    "            \n",
    "        idx_sort = np.argsort(dist_mat, kind='mergesort', axis=0)  # idx_sort.shape = (n,m); dist_mat triée selon les colonnes\n",
    "        # mergesort donne une gestion stable des nombre égaux: \n",
    "        # en cas d'égalité, l'ordre des indices dans l'output est le même que l'ordre dans l'input\n",
    "        \n",
    "        idx_sort_knn = idx_sort[:self.n_neighbors,:] # Redimensionnement avec le nombre de plus proches voisins\n",
    "        return getBestClassFromCount(idx_sort_knn, self.Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantages:<br>\n",
    "- intuitif\n",
    "- aisément paramétrable\n",
    "- nombre de classes quelconques\n",
    "\n",
    "Inconvénients:<br>\n",
    "- très couteux (distances à calculer) => pas adapté pour le big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\widehat{f}_k(x)=\\underset{y \\in \\mathcal{Y}}{\\operatorname{argmax}}(\\Sigma_{j=1}^k \\omega_j \\mathbb{1}\\{y_{r_j}=y\\})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "où $$\\omega_j = e^{-d_j^2/h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: cette variante ne change rien dans le sélection des k-ppv, c'est uniquement au moment de la sélection de la classe majoritaire qu'on affine la sélection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette variante donne plus de poids aux distances très petites. Plus $h$ est petit, plus les petites distances sont favorisées (fonction $exp$ plus pentue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basé sur l'exemple de Google Developers: https://github.com/random-forests/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche à approcher $f: \\mathcal{X} \\to \\mathcal{Y}$ où $\\mathcal{X} \\subset \\mathbb{R}^p$ et $\\mathcal{Y}$ l'ensemble des étiquettes. $\\mathcal{S}$ est l'ensemble d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut parvenir à partitionner l'espace $\\mathcal{X}$ au mieux. Au départ $\\mathcal{X}$ est le noeud (racine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme principal permettant de construire un arbre est le suivant (récursif):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    gain, question = find_best_split(rows)\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    true_branch = build_tree(true_rows)\n",
    "    false_branch = build_tree(false_rows)\n",
    "    return Decision_Node(question, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algo d'optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque ensemble de données, on définit le bon séparateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_gini = gini(rows)\n",
    "    n_features = len(rows[0]) - 1\n",
    "\n",
    "    for col in range(n_features): # Itération sur les variables explicatives\n",
    "\n",
    "        values = set([row[col] for row in rows]) # Itération sur les observations d'une variable explicative\n",
    "\n",
    "        for val in values: # Itération sur les observations uniques\n",
    "\n",
    "            question = Question(col, val)\n",
    "\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "\n",
    "            gain = info_gain(true_rows, false_rows, current_gini)\n",
    "\n",
    "            if gain >= best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "\n",
    "    return best_gain, best_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une <i>question</i> est donc une combinaison (variable explicative, valeur) à partir de laquelle on va regarder les variables à droite ($\\ge$) et à gauche ($\\le$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Séparateur linéaire: l'indice de Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une méthode pour séparer les données est <i>l'indice de Gini</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    counts = class_counts(rows) # Renvoie un dictionnaire d'occurences\n",
    "    impurity = 1\n",
    "    for lbl in counts:\n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'indice de Gini permet de mesurer l'impureté de la séparation. Pour une liste d'éléments, l'indice de Gini représente la proba de mal classer un élément si on le tire au hasard et qu'on le classe au hasard. Autrement dit, la mesure de Gini représente la disparité au sein d'un ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H(S)=\\Sigma_{\\ell=1}^C p_{\\ell}(S)(1-p_{\\ell}(S))$ qu'on peut aussi écrire (plus facile à coder):<br> $H(S)=\\Sigma_{\\ell=1}^C p_{\\ell}(S)-\\Sigma_{\\ell=1}^C p_{\\ell}(S)*p_{\\ell}(S)=1-\\Sigma_{\\ell=1}^C p_{\\ell}(S)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avec $p_{c}(S)=\\frac{1}{n}\\Sigma_{i=1}^n \\mathbb{1}\\{y_i=c\\}$ la fréquence d'une étiquette dans un ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de perte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer la pertinence du split, on utilise <i>information gain</i> qui compare l'impureté d'un état de l'arbre actuel (<i>current_gini</i>) avec l'impureté calculée si on applique un séparateur. Cette deuxième mesure de l'impureté est en fait la fonction de perte qui pondère la mesure de gini sur l'importance de ses enfants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_gini):\n",
    "    p = float(len(left)) / (len(left) + len(right))\n",
    "    return current_gini - (p * gini(left) + (1 - p) * gini(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi toutes les variables et leurs valeurs $(j, \\tau)$, on cherche $(\\widehat{j}, \\widehat{\\tau})$ qui minimisent:\n",
    "\n",
    "$\\mathcal{L}(t_{j,\\tau},S)=\\frac{n_d}{n}H(\\mathcal{D}(S,j,\\tau))+\\frac{n_g}{n}H(\\mathcal{G}(S,j,\\tau))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème s'écrit donc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underset{j \\in \\{1,...,p\\} \\\\\n",
    "\\tau \\in \\mathbb{R}}{\\operatorname{argmin}} \\frac{n_d}{n}H(\\mathcal{D}(S,j,\\tau))+\\frac{n_g}{n}H(\\mathcal{G}(S,j,\\tau))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{D}(S,j,\\tau)=\\{(x,y), t_{j,\\tau} \\ge 0\\}$ l'ensemble des éléments classés à droite => l'inégalité $t_{j,\\tau} \\ge 0$ représente le critère de classification (<i>séparateur linéaire</i>) gauche/droite. Les arbres utilisent donc plusieurs séparateurs linéaires pour construire des frontières de décision non linéaires. Utiliser des séparateurs linéaires orthogonaux à chaque vecteur de base (<font color='orange'>??</font>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$n_d=\\frac{|i \\in [\\![ 1,n ]\\!]: x_i \\in D(j,\\tau) |}{\\{i' \\in [\\![ 1,n ]\\!]: x_{i'} \\in G(j,\\tau) \\cup D(j,\\tau)\\}}=|\\mathcal{D}(S,j,\\tau)|$ est le nombre d'éléments qui ont été classés dans le noeud droit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: le problème global est la minimisation de la fonction de perte, ce qui revient à maximiser la différence d'impureté à chaque test de séparateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le critère d'arrêt c'est lorsque qu'on ne peut pas diminuer la fonction de coût avec un séparateur. Alors, on dit qu'on est dans une feuille."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction de prédiction prend en paramètre la nouvelle observation, ainsi que l'arbre construit précédemment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On parcourt l'arbre jusqu'à arriver à une feuille qui donne les probabilités de résultats associées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):\n",
    "        self.predictions = class_counts(rows) # renvoie un dictionnaire des classes avec leurs occurences (= proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

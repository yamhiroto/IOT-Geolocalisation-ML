HADOOP

Principe de base: haute tolérance aux pannes

HDFS: système de fichiers distibués. Les données sont réparties et répliquées sur le cluster.
MapReduce: paradigme de programmation. C'est une façon de construire des applications distribuées.
YARN: gestionnaire de ressources. Permet de lancer des applications sur le cluster. Parmi ses composantes:
- Resource manager: gère l'ensemble des ressources pour tout le cluster
- Application master: gère les ressources pour une application, négocie ses ressources au RM
- Node manager: monitore les ressources par machine, reporte les informations au RM
fsImage: fichier qui contient les infos de la localisation d'un bloc de données
editLog: fichier qui contient les infos des derniers changements sur les données

Configuration par défaut:
Stockage par bloc de 64Mo
Facteur de réplication = 3

Noeuds master (décident du lieu d'écriture): 
- primary namenode: récupère les fsImage et editLog du client
- secondary namenode: fusionne les fsImage et editLog du client pour en faire un fichier .checkpoint
Noeuds workers:
- datanode

Panne: 
- Un datanode tombe: si le namenode ne recoit plus de heartbeat pendant une certaine durée, les données sont répliquées depuis des copies d'autres datanodes
- Un namenode tombe: le namenode secondaire gère toutes les intéractions avec le cluster


SPARK

Outil de processing et d'analyse de données à grande échelle, codé en Scala, et en open source

++: fonctionne sur un laptop en local (sans cluster manager)
++: stockage des données en RAM (et non sur disque comme Hadoop) = mise en cache des données => accès plus rapide

Utilise une VM

Deux masters
Un job est exécuté par un groupe de workers (plusieurs executors et un driver)

Cluster manager = service externe regroupant l’ensemble des ressources du cluster (i.e. standalone manager, Mesos, YARN)
Master node = noeud sur lequel est installé le cluster manager en mode Standalone (i.e installé sur des conteneurs => plusieurs VM)
Worker node = noeud mis à disposition dans le cluster pour faire tourner une application

Driver program = processus sur lequel tourne le main() de l’application. Il crée le SparkContext
Executor = processus lancé pour une application sur un Worker node. C’est le processus qui exécute les tâches “lourdes” de l’application et stocke en mémoire les résultats intermédiaires.
Application = Application Spark. Elle est constituée d’un driver et d’executors. 
Job = un calcul parallélisé au sein d’une application consistant en un ensemble de stages menant à une Action (ex : collect)
Stage = ensemble de tasks interdépendantes (ex : map puis reduce)
Task = unité de travail distribuée sur un executor
